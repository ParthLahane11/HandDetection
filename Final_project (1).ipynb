{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d87f95a",
   "metadata": {},
   "source": [
    "Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b03b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyDirectInput in c:\\users\\lahan\\anaconda3\\lib\\site-packages (1.0.4)\n",
      "Requirement already satisfied: pyautogui in c:\\users\\lahan\\anaconda3\\lib\\site-packages (0.9.53)\n",
      "Requirement already satisfied: pyscreeze>=0.1.21 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.28)\n",
      "Requirement already satisfied: pymsgbox in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.9)\n",
      "Requirement already satisfied: pygetwindow>=0.0.5 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from pyautogui) (0.0.9)\n",
      "Requirement already satisfied: PyTweening>=1.0.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from pyautogui) (1.0.4)\n",
      "Requirement already satisfied: mouseinfo in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from pyautogui) (0.1.3)\n",
      "Requirement already satisfied: pyrect in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from pygetwindow>=0.0.5->pyautogui) (0.2.0)\n",
      "Requirement already satisfied: pyperclip in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mouseinfo->pyautogui) (1.8.2)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\lahan\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lahan\\anaconda3\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\lahan\\anaconda3\\lib\\site-packages (0.9.2.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mediapipe) (23.3.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mediapipe) (3.7.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mediapipe) (1.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mediapipe) (4.7.0.72)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (22.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lahan\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyDirectInput\n",
    "!pip install pyautogui\n",
    "!pip install tensorflow\n",
    "!pip install scikit-learn\n",
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6243a10a",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c44eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import copy\n",
    "import itertools\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "from collections import deque\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fca8c4",
   "metadata": {},
   "source": [
    "Initialising Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e903bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'model_helper/train_data.csv'\n",
    "model_save_path = 'model_helper/gesturesModel.hdf5'\n",
    "tflite_save_path = 'model_helper/gestureLite.tflite'\n",
    "\n",
    "NUM_CLASSES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280cd72",
   "metadata": {},
   "source": [
    "Training of Hand Gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc6c6b21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_2 (Dropout)         (None, 42)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 20)                860       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,136\n",
      "Trainable params: 1,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 1/24 [>.............................] - ETA: 16s - loss: 1.8684 - accuracy: 0.1562\n",
      "Epoch 1: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 1s 11ms/step - loss: 1.7265 - accuracy: 0.2245 - val_loss: 1.5587 - val_accuracy: 0.4834\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 1.5075 - accuracy: 0.4125\n",
      "Epoch 2: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.5075 - accuracy: 0.4125 - val_loss: 1.3433 - val_accuracy: 0.6575\n",
      "Epoch 3/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.3263 - accuracy: 0.5547\n",
      "Epoch 3: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.3141 - accuracy: 0.5525 - val_loss: 1.1282 - val_accuracy: 0.6546\n",
      "Epoch 4/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.1895 - accuracy: 0.6328\n",
      "Epoch 4: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.1377 - accuracy: 0.6113 - val_loss: 0.9537 - val_accuracy: 0.7123\n",
      "Epoch 5/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 1.0852 - accuracy: 0.6562\n",
      "Epoch 5: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.9927 - accuracy: 0.6694 - val_loss: 0.8033 - val_accuracy: 0.7710\n",
      "Epoch 6/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.9818 - accuracy: 0.6641\n",
      "Epoch 6: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.8802 - accuracy: 0.6948 - val_loss: 0.6768 - val_accuracy: 0.7916\n",
      "Epoch 7/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.8102 - accuracy: 0.7031\n",
      "Epoch 7: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.7916 - accuracy: 0.7190 - val_loss: 0.5837 - val_accuracy: 0.8092\n",
      "Epoch 8/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.7530 - accuracy: 0.7188\n",
      "Epoch 8: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.7327 - val_loss: 0.5138 - val_accuracy: 0.8102\n",
      "Epoch 9/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.6670 - accuracy: 0.7500\n",
      "Epoch 9: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.7513 - val_loss: 0.4599 - val_accuracy: 0.8425\n",
      "Epoch 10/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.6011 - accuracy: 0.7683\n",
      "Epoch 10: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5992 - accuracy: 0.7699 - val_loss: 0.4221 - val_accuracy: 0.8855\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.7804\n",
      "Epoch 11: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5692 - accuracy: 0.7804 - val_loss: 0.3922 - val_accuracy: 0.9100\n",
      "Epoch 12/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.5644 - accuracy: 0.7812\n",
      "Epoch 12: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7944 - val_loss: 0.3708 - val_accuracy: 0.9139\n",
      "Epoch 13/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.5749 - accuracy: 0.8125\n",
      "Epoch 13: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.5059 - accuracy: 0.8166 - val_loss: 0.3470 - val_accuracy: 0.9315\n",
      "Epoch 14/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.5190 - accuracy: 0.8203\n",
      "Epoch 14: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.8208 - val_loss: 0.3292 - val_accuracy: 0.9432\n",
      "Epoch 15/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.6305 - accuracy: 0.7578\n",
      "Epoch 15: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4765 - accuracy: 0.8143 - val_loss: 0.3166 - val_accuracy: 0.9413\n",
      "Epoch 16/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.4048 - accuracy: 0.8672\n",
      "Epoch 16: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.8225 - val_loss: 0.2994 - val_accuracy: 0.9491\n",
      "Epoch 17/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.4756 - accuracy: 0.8125\n",
      "Epoch 17: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.8273 - val_loss: 0.2886 - val_accuracy: 0.9384\n",
      "Epoch 18/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3859 - accuracy: 0.8828\n",
      "Epoch 18: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8355 - val_loss: 0.2758 - val_accuracy: 0.9511\n",
      "Epoch 19/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3605 - accuracy: 0.8672\n",
      "Epoch 19: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4179 - accuracy: 0.8427 - val_loss: 0.2624 - val_accuracy: 0.9609\n",
      "Epoch 20/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.4036 - accuracy: 0.8536\n",
      "Epoch 20: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.4027 - accuracy: 0.8538 - val_loss: 0.2544 - val_accuracy: 0.9530\n",
      "Epoch 21/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.4361 - accuracy: 0.8516\n",
      "Epoch 21: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8597 - val_loss: 0.2448 - val_accuracy: 0.9530\n",
      "Epoch 22/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3724 - accuracy: 0.8516\n",
      "Epoch 22: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8564 - val_loss: 0.2295 - val_accuracy: 0.9579\n",
      "Epoch 23/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.4824 - accuracy: 0.8359\n",
      "Epoch 23: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8567 - val_loss: 0.2303 - val_accuracy: 0.9638\n",
      "Epoch 24/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3615 - accuracy: 0.8672\n",
      "Epoch 24: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3721 - accuracy: 0.8642 - val_loss: 0.2203 - val_accuracy: 0.9560\n",
      "Epoch 25/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3739 - accuracy: 0.8672\n",
      "Epoch 25: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3521 - accuracy: 0.8796 - val_loss: 0.2068 - val_accuracy: 0.9736\n",
      "Epoch 26/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3529 - accuracy: 0.8672\n",
      "Epoch 26: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8779 - val_loss: 0.2030 - val_accuracy: 0.9658\n",
      "Epoch 27/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3072 - accuracy: 0.9062\n",
      "Epoch 27: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3450 - accuracy: 0.8714 - val_loss: 0.1982 - val_accuracy: 0.9658\n",
      "Epoch 28/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3090 - accuracy: 0.9062\n",
      "Epoch 28: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3371 - accuracy: 0.8884 - val_loss: 0.1931 - val_accuracy: 0.9677\n",
      "Epoch 29/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3419 - accuracy: 0.8359\n",
      "Epoch 29: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 0.8809 - val_loss: 0.1899 - val_accuracy: 0.9677\n",
      "Epoch 30/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2932 - accuracy: 0.9062\n",
      "Epoch 30: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3133 - accuracy: 0.8903 - val_loss: 0.1862 - val_accuracy: 0.9648\n",
      "Epoch 31/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8906\n",
      "Epoch 31: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3202 - accuracy: 0.8796 - val_loss: 0.1770 - val_accuracy: 0.9755\n",
      "Epoch 32/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3383 - accuracy: 0.8750\n",
      "Epoch 32: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3135 - accuracy: 0.8874 - val_loss: 0.1803 - val_accuracy: 0.9677\n",
      "Epoch 33/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2617 - accuracy: 0.8984\n",
      "Epoch 33: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8978 - val_loss: 0.1666 - val_accuracy: 0.9765\n",
      "Epoch 34/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3640 - accuracy: 0.8438\n",
      "Epoch 34: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2975 - accuracy: 0.8946 - val_loss: 0.1712 - val_accuracy: 0.9716\n",
      "Epoch 35/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2454 - accuracy: 0.9062\n",
      "Epoch 35: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.3049 - accuracy: 0.8894 - val_loss: 0.1547 - val_accuracy: 0.9775\n",
      "Epoch 36/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2687 - accuracy: 0.8828\n",
      "Epoch 36: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2967 - accuracy: 0.8943 - val_loss: 0.1584 - val_accuracy: 0.9746\n",
      "Epoch 37/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3102 - accuracy: 0.8984\n",
      "Epoch 37: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2876 - accuracy: 0.8965 - val_loss: 0.1573 - val_accuracy: 0.9746\n",
      "Epoch 38/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3911 - accuracy: 0.8750\n",
      "Epoch 38: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2814 - accuracy: 0.9021 - val_loss: 0.1548 - val_accuracy: 0.9765\n",
      "Epoch 39/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2861 - accuracy: 0.8828\n",
      "Epoch 39: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2895 - accuracy: 0.8946 - val_loss: 0.1520 - val_accuracy: 0.9755\n",
      "Epoch 40/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2916 - accuracy: 0.8984\n",
      "Epoch 40: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.9027 - val_loss: 0.1481 - val_accuracy: 0.9775\n",
      "Epoch 41/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2255 - accuracy: 0.9141\n",
      "Epoch 41: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2601 - accuracy: 0.9106 - val_loss: 0.1420 - val_accuracy: 0.9804\n",
      "Epoch 42/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1983 - accuracy: 0.9062\n",
      "Epoch 42: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.9089 - val_loss: 0.1422 - val_accuracy: 0.9775\n",
      "Epoch 43/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.9106\n",
      "Epoch 43: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2636 - accuracy: 0.9106 - val_loss: 0.1372 - val_accuracy: 0.9795\n",
      "Epoch 44/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2695 - accuracy: 0.9219\n",
      "Epoch 44: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2592 - accuracy: 0.9063 - val_loss: 0.1383 - val_accuracy: 0.9804\n",
      "Epoch 45/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2144 - accuracy: 0.8984\n",
      "Epoch 45: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2778 - accuracy: 0.9024 - val_loss: 0.1320 - val_accuracy: 0.9804\n",
      "Epoch 46/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2696 - accuracy: 0.9219\n",
      "Epoch 46: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2528 - accuracy: 0.9158 - val_loss: 0.1394 - val_accuracy: 0.9775\n",
      "Epoch 47/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2228 - accuracy: 0.9297\n",
      "Epoch 47: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2704 - accuracy: 0.9076 - val_loss: 0.1297 - val_accuracy: 0.9804\n",
      "Epoch 48/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2744 - accuracy: 0.8828\n",
      "Epoch 48: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.9210 - val_loss: 0.1298 - val_accuracy: 0.9814\n",
      "Epoch 49/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2261 - accuracy: 0.9062\n",
      "Epoch 49: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2545 - accuracy: 0.9109 - val_loss: 0.1336 - val_accuracy: 0.9746\n",
      "Epoch 50/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2182 - accuracy: 0.9141\n",
      "Epoch 50: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9194 - val_loss: 0.1290 - val_accuracy: 0.9785\n",
      "Epoch 51/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2063 - accuracy: 0.9375\n",
      "Epoch 51: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2437 - accuracy: 0.9207 - val_loss: 0.1261 - val_accuracy: 0.9804\n",
      "Epoch 52/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2360 - accuracy: 0.9141\n",
      "Epoch 52: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2453 - accuracy: 0.9102 - val_loss: 0.1145 - val_accuracy: 0.9814\n",
      "Epoch 53/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2824 - accuracy: 0.8906\n",
      "Epoch 53: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2459 - accuracy: 0.9148 - val_loss: 0.1155 - val_accuracy: 0.9804\n",
      "Epoch 54/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2744 - accuracy: 0.9062\n",
      "Epoch 54: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2375 - accuracy: 0.9148 - val_loss: 0.1175 - val_accuracy: 0.9785\n",
      "Epoch 55/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2768 - accuracy: 0.8984\n",
      "Epoch 55: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2291 - accuracy: 0.9223 - val_loss: 0.1078 - val_accuracy: 0.9804\n",
      "Epoch 56/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.3194 - accuracy: 0.8984\n",
      "Epoch 56: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.9207 - val_loss: 0.1159 - val_accuracy: 0.9795\n",
      "Epoch 57/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2418 - accuracy: 0.9219\n",
      "Epoch 57: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9184 - val_loss: 0.1098 - val_accuracy: 0.9795\n",
      "Epoch 58/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2750 - accuracy: 0.8906\n",
      "Epoch 58: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2376 - accuracy: 0.9204 - val_loss: 0.1123 - val_accuracy: 0.9785\n",
      "Epoch 59/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2851 - accuracy: 0.8906\n",
      "Epoch 59: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2308 - accuracy: 0.9220 - val_loss: 0.1061 - val_accuracy: 0.9814\n",
      "Epoch 60/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2150 - accuracy: 0.9141\n",
      "Epoch 60: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2221 - accuracy: 0.9220 - val_loss: 0.1178 - val_accuracy: 0.9736\n",
      "Epoch 61/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1533 - accuracy: 0.9531\n",
      "Epoch 61: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.9116 - val_loss: 0.1143 - val_accuracy: 0.9785\n",
      "Epoch 62/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2387 - accuracy: 0.9062\n",
      "Epoch 62: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2403 - accuracy: 0.9158 - val_loss: 0.1045 - val_accuracy: 0.9804\n",
      "Epoch 63/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2433 - accuracy: 0.9219\n",
      "Epoch 63: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2365 - accuracy: 0.9233 - val_loss: 0.1169 - val_accuracy: 0.9765\n",
      "Epoch 64/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2280 - accuracy: 0.9141\n",
      "Epoch 64: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2296 - accuracy: 0.9184 - val_loss: 0.1188 - val_accuracy: 0.9755\n",
      "Epoch 65/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2827 - accuracy: 0.8828\n",
      "Epoch 65: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9253 - val_loss: 0.1073 - val_accuracy: 0.9765\n",
      "Epoch 66/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2004 - accuracy: 0.9219\n",
      "Epoch 66: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2240 - accuracy: 0.9187 - val_loss: 0.1080 - val_accuracy: 0.9755\n",
      "Epoch 67/100\n",
      "23/24 [===========================>..] - ETA: 0s - loss: 0.2228 - accuracy: 0.9253\n",
      "Epoch 67: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2236 - accuracy: 0.9249 - val_loss: 0.1033 - val_accuracy: 0.9765\n",
      "Epoch 68/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1261 - accuracy: 0.9531\n",
      "Epoch 68: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2126 - accuracy: 0.9292 - val_loss: 0.1056 - val_accuracy: 0.9775\n",
      "Epoch 69/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.9233\n",
      "Epoch 69: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2250 - accuracy: 0.9233 - val_loss: 0.1024 - val_accuracy: 0.9775\n",
      "Epoch 70/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1732 - accuracy: 0.9453\n",
      "Epoch 70: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9259 - val_loss: 0.1049 - val_accuracy: 0.9765\n",
      "Epoch 71/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2432 - accuracy: 0.8984\n",
      "Epoch 71: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2071 - accuracy: 0.9308 - val_loss: 0.1057 - val_accuracy: 0.9765\n",
      "Epoch 72/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2345 - accuracy: 0.8984\n",
      "Epoch 72: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2115 - accuracy: 0.9220 - val_loss: 0.0976 - val_accuracy: 0.9775\n",
      "Epoch 73/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2404 - accuracy: 0.9219\n",
      "Epoch 73: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2085 - accuracy: 0.9279 - val_loss: 0.1007 - val_accuracy: 0.9765\n",
      "Epoch 74/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1705 - accuracy: 0.9375\n",
      "Epoch 74: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2129 - accuracy: 0.9266 - val_loss: 0.1069 - val_accuracy: 0.9775\n",
      "Epoch 75/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1648 - accuracy: 0.9375\n",
      "Epoch 75: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2042 - accuracy: 0.9272 - val_loss: 0.0947 - val_accuracy: 0.9824\n",
      "Epoch 76/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2566 - accuracy: 0.9297\n",
      "Epoch 76: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1958 - accuracy: 0.9295 - val_loss: 0.0980 - val_accuracy: 0.9795\n",
      "Epoch 77/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.9230\n",
      "Epoch 77: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 0.2114 - accuracy: 0.9230 - val_loss: 0.0963 - val_accuracy: 0.9775\n",
      "Epoch 78/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2777 - accuracy: 0.9141\n",
      "Epoch 78: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.9279 - val_loss: 0.0938 - val_accuracy: 0.9795\n",
      "Epoch 79/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2285 - accuracy: 0.9375\n",
      "Epoch 79: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2043 - accuracy: 0.9305 - val_loss: 0.1027 - val_accuracy: 0.9785\n",
      "Epoch 80/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2343 - accuracy: 0.9297\n",
      "Epoch 80: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2022 - accuracy: 0.9341 - val_loss: 0.0927 - val_accuracy: 0.9795\n",
      "Epoch 81/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1948 - accuracy: 0.9297\n",
      "Epoch 81: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9275 - val_loss: 0.1103 - val_accuracy: 0.9736\n",
      "Epoch 82/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1993 - accuracy: 0.9453\n",
      "Epoch 82: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2134 - accuracy: 0.9269 - val_loss: 0.0881 - val_accuracy: 0.9804\n",
      "Epoch 83/100\n",
      "19/24 [======================>.......] - ETA: 0s - loss: 0.1943 - accuracy: 0.9334\n",
      "Epoch 83: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1913 - accuracy: 0.9364 - val_loss: 0.0974 - val_accuracy: 0.9795\n",
      "Epoch 84/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1689 - accuracy: 0.9531\n",
      "Epoch 84: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1963 - accuracy: 0.9331 - val_loss: 0.0943 - val_accuracy: 0.9795\n",
      "Epoch 85/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2209 - accuracy: 0.9062\n",
      "Epoch 85: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.2078 - accuracy: 0.9275 - val_loss: 0.0967 - val_accuracy: 0.9765\n",
      "Epoch 86/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1648 - accuracy: 0.9453\n",
      "Epoch 86: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9364 - val_loss: 0.0971 - val_accuracy: 0.9755\n",
      "Epoch 87/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1910 - accuracy: 0.9531\n",
      "Epoch 87: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 0.9341 - val_loss: 0.0966 - val_accuracy: 0.9795\n",
      "Epoch 88/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1844 - accuracy: 0.9375\n",
      "Epoch 88: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2077 - accuracy: 0.9337 - val_loss: 0.0885 - val_accuracy: 0.9795\n",
      "Epoch 89/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2168 - accuracy: 0.9141\n",
      "Epoch 89: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2042 - accuracy: 0.9292 - val_loss: 0.1037 - val_accuracy: 0.9755\n",
      "Epoch 90/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1988 - accuracy: 0.9453\n",
      "Epoch 90: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2088 - accuracy: 0.9279 - val_loss: 0.0922 - val_accuracy: 0.9795\n",
      "Epoch 91/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1644 - accuracy: 0.9453\n",
      "Epoch 91: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1940 - accuracy: 0.9354 - val_loss: 0.0995 - val_accuracy: 0.9775\n",
      "Epoch 92/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2362 - accuracy: 0.9375\n",
      "Epoch 92: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1954 - accuracy: 0.9328 - val_loss: 0.0934 - val_accuracy: 0.9775\n",
      "Epoch 93/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1064 - accuracy: 0.9688\n",
      "Epoch 93: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1974 - accuracy: 0.9341 - val_loss: 0.1022 - val_accuracy: 0.9746\n",
      "Epoch 94/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2419 - accuracy: 0.9141\n",
      "Epoch 94: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1966 - accuracy: 0.9337 - val_loss: 0.0963 - val_accuracy: 0.9765\n",
      "Epoch 95/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2209 - accuracy: 0.9141\n",
      "Epoch 95: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1879 - accuracy: 0.9347 - val_loss: 0.0921 - val_accuracy: 0.9775\n",
      "Epoch 96/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2944 - accuracy: 0.8984\n",
      "Epoch 96: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 0.1983 - accuracy: 0.9334 - val_loss: 0.0845 - val_accuracy: 0.9795\n",
      "Epoch 97/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1983 - accuracy: 0.9297\n",
      "Epoch 97: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2058 - accuracy: 0.9292 - val_loss: 0.0956 - val_accuracy: 0.9775\n",
      "Epoch 98/100\n",
      "24/24 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9367\n",
      "Epoch 98: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1760 - accuracy: 0.9367 - val_loss: 0.1045 - val_accuracy: 0.9697\n",
      "Epoch 99/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.1823 - accuracy: 0.9375\n",
      "Epoch 99: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.2016 - accuracy: 0.9360 - val_loss: 0.0962 - val_accuracy: 0.9775\n",
      "Epoch 100/100\n",
      " 1/24 [>.............................] - ETA: 0s - loss: 0.2417 - accuracy: 0.9219\n",
      "Epoch 100: saving model to model_helper\\gesturesModel.hdf5\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 0.1906 - accuracy: 0.9422 - val_loss: 0.0946 - val_accuracy: 0.9775\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9775\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "[9.7078192e-01 1.2624536e-02 3.2500857e-06 3.9385850e-05 1.8640565e-04\n",
      " 1.6364528e-02]\n",
      "0\n",
      "32/32 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\lahan\\AppData\\Local\\Temp\\tmpaqbn7k5e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\lahan\\AppData\\Local\\Temp\\tmpaqbn7k5e\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.7078192e-01 1.2624540e-02 3.2500820e-06 3.9385886e-05 1.8640583e-04\n",
      " 1.6364533e-02]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "train_data = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
    "train_label = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, train_size=0.75)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "model.summary()\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")\n",
    "\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "model.save(model_save_path, include_optimizer=False)\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))\n",
    "\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9448c350",
   "metadata": {},
   "source": [
    "Defining Gesture Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6328430e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gestureClassifier(object):\n",
    "    def __init__(self, model_path='model_helper/gestureLite.tflite',num_threads=1,):\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path, num_threads=num_threads)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "\n",
    "    def __call__(self, landmark_list,):\n",
    "        input_details_tensor_index = self.input_details[0]['index']\n",
    "        self.interpreter.set_tensor(input_details_tensor_index, np.array([landmark_list], dtype=np.float32))\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        output_details_tensor_index = self.output_details[0]['index']\n",
    "        result = self.interpreter.get_tensor(output_details_tensor_index)\n",
    "        result_index = np.argmax(np.squeeze(result))\n",
    "        return result_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8832e4",
   "metadata": {},
   "source": [
    "Drawing and Preprocessing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ced4b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(image, landmarks, h, w):\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * w), w - 1)\n",
    "        landmark_y = min(int(landmark.y * h), h - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(landmark_array)\n",
    "\n",
    "    return [x, y, x + w, y + h]\n",
    "\n",
    "\n",
    "def landmarks(image, landmarks, h, w):\n",
    "    landmark_point = []\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * w), w - 1)\n",
    "        landmark_y = min(int(landmark.y * h), h - 1)\n",
    "\n",
    "        landmark_point.append([landmark_x, landmark_y])\n",
    "\n",
    "    return landmark_point\n",
    "\n",
    "\n",
    "def preprocessing(landmark_list):\n",
    "    temp_landmark_list = copy.deepcopy(landmark_list)\n",
    "\n",
    "    base_x, base_y = 0, 0\n",
    "    for index, landmark_point in enumerate(temp_landmark_list):\n",
    "        if index == 0:\n",
    "            base_x, base_y = landmark_point[0], landmark_point[1]\n",
    "\n",
    "        temp_landmark_list[index][0] = temp_landmark_list[index][0] - base_x\n",
    "        temp_landmark_list[index][1] = temp_landmark_list[index][1] - base_y\n",
    "\n",
    "    temp_landmark_list = list(\n",
    "        itertools.chain.from_iterable(temp_landmark_list))\n",
    "\n",
    "    max_value = max(list(map(abs, temp_landmark_list)))\n",
    "\n",
    "\n",
    "    temp_landmark_list = list(map(lambda x:x/max_value, temp_landmark_list))\n",
    "\n",
    "    return temp_landmark_list\n",
    "\n",
    "def draw_info_text(image, brect, handedness, hand_sign_text):\n",
    "    cv.rectangle(image, (brect[0], brect[1]), (brect[2], brect[1] - 22),\n",
    "                 (0, 0, 0), -1)\n",
    "\n",
    "    info_text = handedness.classification[0].label[0:]\n",
    "    if hand_sign_text != \"\":\n",
    "        info_text = info_text + ':' + hand_sign_text\n",
    "    cv.putText(image, info_text, (brect[0] + 5, brect[1] - 4),\n",
    "               cv.FONT_HERSHEY_SIMPLEX, 0.6, (100, 220, 50), 1, cv.LINE_AA)\n",
    "\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a176a91",
   "metadata": {},
   "source": [
    "Describe Cam Enviornment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb7d54c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_device = 0\n",
    "cap_width = 640\n",
    "cap_height = 320\n",
    "\n",
    "use_static_image_mode = True\n",
    "min_detection_confidence = 0.7\n",
    "min_tracking_confidence = 0.5\n",
    "\n",
    "use_brect = True\n",
    "\n",
    "cap=cv.VideoCapture(0,cv.CAP_DSHOW)\n",
    "cap.set(cv.CAP_PROP_FRAME_WIDTH, cap_width)\n",
    "cap.set(cv.CAP_PROP_FRAME_HEIGHT,cap_height)\n",
    "cap.set(cv.CAP_PROP_FPS, 30)\n",
    "cap.set(cv.CAP_PROP_FOURCC,cv.VideoWriter_fourcc(*'MJPG'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b715973",
   "metadata": {},
   "source": [
    "Classification and Game Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "330f81c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=use_static_image_mode,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=min_detection_confidence,\n",
    "    min_tracking_confidence=min_tracking_confidence,\n",
    ")\n",
    "\n",
    "gesture_classifier = gestureClassifier()\n",
    "\n",
    "with open('model_helper/gameActions.csv', encoding='utf-8-sig') as f:\n",
    "    gesture_classifier_labels = csv.reader(f)\n",
    "    gesture_classifier_labels = [row[0] for row in gesture_classifier_labels]\n",
    "\n",
    "while True:\n",
    "\n",
    "    key = cv.waitKey(10)\n",
    "    if key == 27:\n",
    "        break\n",
    "    ret, image = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    image = cv.flip(image, 1)\n",
    "    debug_image = copy.deepcopy(image)\n",
    "\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    if results.multi_hand_landmarks is not None:\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks, results.multi_handedness):\n",
    "            height, width =  debug_image.shape[0], debug_image.shape[1]\n",
    "            brect = draw_rect(debug_image, hand_landmarks, height , width)\n",
    "            landmark_list = landmarks(debug_image, hand_landmarks, height, width)\n",
    "            preprocessed_data = preprocessing(\n",
    "                landmark_list)\n",
    "\n",
    "            hand_sign_id = gesture_classifier(preprocessed_data)\n",
    "\n",
    "            if str(hand_sign_id) == '0':\n",
    "                pyautogui.press('g')\n",
    "            if str(hand_sign_id) == '1':\n",
    "                pyautogui.press('a')\n",
    "            if str(hand_sign_id) == '2':\n",
    "                pyautogui.press('d')\n",
    "            if str(hand_sign_id) == '3':\n",
    "                pyautogui.press('w')\n",
    "            if str(hand_sign_id) == '4':\n",
    "                pyautogui.press('s')\n",
    "            if str(hand_sign_id) == '5':\n",
    "                pyautogui.press('f')\n",
    "\n",
    "            debug_image = draw_info_text(debug_image, brect, handedness, gesture_classifier_labels[hand_sign_id])\n",
    "\n",
    "    cv.imshow('Hand controller', debug_image)\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
